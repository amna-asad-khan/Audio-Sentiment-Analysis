# ğŸµ Audio Sentiment Analysis

## ğŸ“Œ Project Overview
This project develops and evaluates a sentiment analysis pipeline for **audio recordings**.  
It uses the **CREMA-D dataset** to extract features such as **MFCCs, Chroma, and Spectral properties**,  
and trains several machine learning models to classify emotions in speech.

---

## âœ¨ Features
- ğŸ¤ Audio preprocessing for noise reduction
- ğŸ¶ Feature extraction using MFCCs, Chroma, and Spectral features
- ğŸ¤– Models implemented:
  - Logistic Regression
  - Naive Bayes
  - K-Nearest Neighbors (KNN)
  - Support Vector Machine (SVM)
  - Multi-Layer Perceptron (MLP)
- ğŸ“Š Evaluation metrics: Accuracy, F1-score, Confusion Matrices
- ğŸ–¥ï¸ Interactive Jupyter Notebook to experiment with different models

---

## ğŸ“š Dataset
We used the [CREMA-D dataset](https://www.kaggle.com/datasets/ejlok1/cremad),  
which contains **7,442 audio samples** with six labeled emotions:
- Angry ğŸ˜ 
- Happy ğŸ˜ƒ
- Sad ğŸ˜¢
- Neutral ğŸ˜
- Fear ğŸ˜¨
- Disgust ğŸ¤¢


---
## ğŸ“Š Results
- The MLP model achieved the highest accuracy among all tested models.
- Class imbalance affected minority classes such as *fear* and *disgust*.

![Confusion Matrix](images/confusion_matrix.png)

![Training Graph](images/training_plot.png)



